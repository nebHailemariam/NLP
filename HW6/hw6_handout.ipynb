{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YId1X55ZPDWB"
      },
      "source": [
        "# Neural Machine Translation using Seq2Seq Models\n",
        "\n",
        "In HW06, we will be training our own machine translation system. We will use an LSTM encoder decoder model and train it with Pytorch.\n",
        "\n",
        "Make sure you are using a GPU. Go to Runtime -> Change Runtime Type -> GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQy46o98kAfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cac317b-1a69-468d-afa0-c6db8396f4d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.9/dist-packages (2.3.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (0.1.97)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from sacrebleu) (4.9.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from sacrebleu) (2022.10.31)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from sacrebleu) (1.22.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.9/dist-packages (from sacrebleu) (0.8.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.9/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.9/dist-packages (from sacrebleu) (2.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00jNulTjyG72"
      },
      "source": [
        "We will use the TED 2013 English-Mandarin parralel dataset. We have done some cleaning and preprocessing for you. We have also created the train, dev, and test splits. Upload the data from the handout and unzip the file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# !unzip /content/drive/MyDrive/nlp_hw6/data.zip"
      ],
      "metadata": {
        "id": "x_UW3sA0XGBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu9aGskp58pS"
      },
      "source": [
        "Import the libraries we will use. After running the cell below, if your notebook is configured to run on GPU, you should see a `device(type='cuda')` output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2QfJZy3cygL",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0520279c-117f-4491-b360-72f1aaaf531f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device being used: cuda\n"
          ]
        }
      ],
      "source": [
        "import operator\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "\n",
        "import numpy as np\n",
        "import sentencepiece as spm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sacrebleu.metrics import BLEU, CHRF\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "device = torch.device(device)\n",
        "print(f\"Device being used: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFriOo4dyVC-"
      },
      "source": [
        "## Preprocessing and Tokenization\n",
        "\n",
        "We will use Sentencepiece to train BPE tokenization models for both the source and target languages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsL4_BeHga-s"
      },
      "source": [
        "Define a function to load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MoLDWprMAav"
      },
      "outputs": [],
      "source": [
        "def load_dataset(lang1, lang2, max_length=10, root=\"data\", split=\"train\"):\n",
        "    ipt1 = os.path.join(root, \".\".join([split, lang1]))\n",
        "    ipt2 = os.path.join(root, \".\".join([split, lang2]))\n",
        "    corpus = {lang1: [], lang2: []}\n",
        "    with open(ipt1) as f1, open(ipt2) as f2:\n",
        "        for sent1, sent2 in zip(f1, f2):\n",
        "            clean1 = sent1.strip()\n",
        "            clean2 = sent2.strip()\n",
        "            if len(clean1) == 0 or len(clean2) == 0:\n",
        "                continue\n",
        "            corpus[lang1].append(clean1)\n",
        "            corpus[lang2].append(clean2)\n",
        "    return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t77jfic9MAav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207a4658-aef1-44a4-efe4-e96fab4310de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_data['en'])=42708, len(train_data['zh'])=42708\n"
          ]
        }
      ],
      "source": [
        "train_data = load_dataset('en', 'zh', split=\"train\")\n",
        "valid_data = load_dataset('en', 'zh', split=\"valid\")\n",
        "assert len(train_data['en']) == 42708, \"Should be 42708\"\n",
        "assert len(train_data['zh']) == 42708, \"Should be 42708\"\n",
        "assert len(valid_data['en']) == 5338, \"Should be 5338\"\n",
        "assert len(valid_data['zh']) == 5338, \"Should be 5338\"\n",
        "print(f\"{len(train_data['en'])=}, {len(train_data['zh'])=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIWufnOogsK7"
      },
      "source": [
        "Train the Sentencepiece models. Training the Mandarin model will take longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7T12yXjMAav"
      },
      "outputs": [],
      "source": [
        "spm.SentencePieceTrainer.train(\n",
        "    sentence_iterator=iter(train_data[\"en\"]),\n",
        "    model_prefix=\"en-zh.en\",\n",
        "    vocab_size=5000,\n",
        "    model_type=\"bpe\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgtt0saFMAav"
      },
      "outputs": [],
      "source": [
        "spm.SentencePieceTrainer.train(\n",
        "    sentence_iterator=iter(train_data[\"zh\"]),\n",
        "    model_prefix=\"en-zh.zh\",\n",
        "    vocab_size=5000,\n",
        "    model_type=\"bpe\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orQ6EWFOdjaC"
      },
      "source": [
        "### Checkpoint 1\n",
        "\n",
        "Test your newly trained Sentencepiece models on a snippet of the dataset. You can download the model files so that you don't have to redo the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmmXD5HOMAaw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0466bd03-03b8-4fd1-fad0-a6f0debc2cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['▁What', '▁gives', '▁us', '▁the', '▁cou', 'rage', '?'], ['▁\"', 'C', 'ome', '▁on', '.', '▁You', '▁got', '▁a', '▁t', 'icket', '?\"'], ['▁P', 'ush', '▁it', '▁and', '▁it', '▁becomes', '▁house', '▁sha', 'ped', '.'], ['▁R', 'est', 'ing', '▁on', '▁the', '▁sa', 'uc', 'er', '▁were', '▁two', '▁pack', 'ets', '▁of', '▁su', 'g', 'ar', '.'], ['▁Now', ',', '▁here', '▁is', '▁K', 'ing', '▁C', 'n', 'ut', ',', '▁king', '▁a', '▁thousand', '▁years', '▁ago', '.'], ['▁And', '▁they', '▁say', ',', '▁\"', 'K', 'e', 'ep', '▁your', '▁laws', '▁off', '▁my', '▁body', '.\"'], ['▁The', '▁Bill', '▁G', 'ates', '▁song', '!'], ['▁You', \"'\", 're', '▁critical', '.'], ['▁Okay', ',', '▁so', '▁you', '▁smile', ',', '▁fr', 'own', 'ing', '.'], ['▁Because', '▁this', '▁didn', \"'\", 't', '▁want', '▁to', '▁be', '▁a', '▁surprise', '.']]\n"
          ]
        }
      ],
      "source": [
        "en_sp = spm.SentencePieceProcessor(model_file=\"en-zh.en.model\")\n",
        "assert en_sp.encode_as_pieces(train_data[\"en\"][0]) == ['▁What', '▁gives', '▁us', '▁the', '▁cou', 'rage', '?']\n",
        "print(en_sp.encode_as_pieces(train_data[\"en\"][:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTXXmUJ5MAaw",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec067c8-2e27-4b4a-a68b-b03399bf6efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['▁什么', '给', '予', '了我', '这', '项', '勇', '气', '?'], ['▁“', '哦', '说', '吧', ',', '你', '吃', '罚', '单', '了', '?”'], ['▁', '推', '一下', ',', '它', '又', '成了', '屋', '形'], ['▁只', '见', '茶', '托', '上', '赫', '然', '躺', '着', '▁', '两', '小', '包', '糖', '。'], ['▁现在', '看到的是', '克', '努', '特', '王', ',', '1', '000', '年前', '的', '国', '王', '。'], ['▁他们说', '”', '不要', '给我', '这些', '法', '律', '。“'], ['▁比', '尔', '盖', '茨', '之', '歌', '!'], ['▁你', '有些', '怀', '疑', '.'], ['▁O', 'K', ',', '当', '你', '▁', '微', '笑', '和', '皱', '眉', '头', '时', '。'], ['▁因为我们', '不想', '这个项目', '让', '大家', '觉得', '突然', '。']]\n"
          ]
        }
      ],
      "source": [
        "zh_sp = spm.SentencePieceProcessor(model_file=\"en-zh.zh.model\")\n",
        "assert zh_sp.encode_as_pieces(train_data[\"zh\"][0]) == ['▁什么', '给', '予', '了我', '这', '项', '勇', '气', '?']\n",
        "print(zh_sp.encode_as_pieces(train_data[\"zh\"][:10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHp1PYyUg9NM"
      },
      "source": [
        "## Model Definitions\n",
        "\n",
        "Now we need to define our models. In general, we need to inherit the `torch.nn.Module` class, define an `__init__` function where we create the layers in our model, and a `forward` function where we compute the outputs from the inputs.\n",
        "\n",
        "You can check [here](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) for a more detailed tutorial on building neural networks in Pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BVBkJVczD3D"
      },
      "source": [
        "For the encoder, we use a bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk_1ZuLWj5N9"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, emb_size, hidden_size, num_layers=2, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        # TO-DO: Create nn.Embedding layer with (input_size, emb_size)\n",
        "        self.embedding = torch.nn.Embedding(input_size, emb_size)\n",
        "\n",
        "        # TO-DO: Create nn.LSTM layer with (emb_size, hidden_size)\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=emb_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # TO-DO: Run the input through the embedding layer\n",
        "        embedded = self.embedding(inputs)\n",
        "\n",
        "        # TO-DO: Run both the embedded and hidden through LSTM\n",
        "        output, hidden = self.lstm(embedded)\n",
        "\n",
        "        # Return both output and hidden\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMBcVqtBkdm5"
      },
      "outputs": [],
      "source": [
        "# Encoder test\n",
        "dummy_in = torch.randint(1, 10, (6, 5), device=device)\n",
        "dummy_encoder = EncoderRNN(10, 300, 1024).to(device)\n",
        "dummy_out, dummy_hid = dummy_encoder.forward(dummy_in)\n",
        "assert dummy_out.shape == (6, 5, 2 * 1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ekxl5MczGpy"
      },
      "source": [
        "We use an LSTM decoder. The model definitions will be very similar except that we add a linear layer to project the hidden representations to the output tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxuXcv_4kgLk"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(torch.nn.Module):\n",
        "    def __init__(self, output_size, emb_size, hidden_size, num_layers=4, dropout=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        # TO-DO: Create nn.Embedding layer with (output_size, emb_size)\n",
        "        self.embedding = torch.nn.Embedding(output_size, emb_size)\n",
        "\n",
        "        # TO-DO: Create nn.LSTM layer with (emb_size, hidden_size)\n",
        "        # Make sure to set batch_first=True\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=emb_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=False,\n",
        "            dropout=dropout,\n",
        "        )\n",
        "\n",
        "        # TO-DO: Create a nn.Linear layer with (hidden_size, output_size)\n",
        "        self.proj = torch.nn.Linear(in_features=hidden_size, out_features=output_size)\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "        # TO-DO: Run the input through the embedding layer\n",
        "        inputs = self.embedding(inputs)\n",
        "\n",
        "        # TO-DO: Run both the input and hidden through LSTM\n",
        "        outputs, hidden = self.lstm(inputs, hidden)\n",
        "\n",
        "        # TO-DO: Run the output through the linear layer\n",
        "        outputs = self.proj(outputs)\n",
        "\n",
        "        # Return both output and hidden\n",
        "        return outputs, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4zGCwlmJcPI"
      },
      "source": [
        "### Checkpoint 2\n",
        "\n",
        "You should now be able to pass data through both the encoder and decoder.\n",
        "\n",
        "Note that the number of layers of the decoder should double that of the encoder, because the encoder is bidirectional while the decoder is not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_2N0WjiIxDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd82b4d-1994-4e48-9b93-be7f35f323b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 7, 10])\n"
          ]
        }
      ],
      "source": [
        "# Decoder test\n",
        "dummy_out = torch.randint(1, 10, (6, 7), device=device)\n",
        "dummy_decoder = DecoderRNN(10, 300, 1024).to(device)\n",
        "dummy_pred, _ = dummy_decoder.forward(dummy_out, dummy_hid)\n",
        "print(dummy_pred.shape)\n",
        "assert dummy_pred.shape == (6, 7, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaYxxOpPzJII"
      },
      "source": [
        "## Training the Model\n",
        "\n",
        "We now prepare the training loop. We need to first define a datastructure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUKin5LkMAay"
      },
      "outputs": [],
      "source": [
        "class MTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, src, tgt):\n",
        "        self.src = src\n",
        "        self.tgt = tgt\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\"src\": self.src[index], \"tgt\": self.tgt[index]}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmpGgSvXMAay"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    src = torch.nn.utils.rnn.pad_sequence(\n",
        "        [torch.tensor(b[\"src\"]) for b in batch], batch_first=True\n",
        "    )\n",
        "    tgt = torch.nn.utils.rnn.pad_sequence(\n",
        "        [torch.tensor(b[\"tgt\"]) for b in batch], batch_first=True\n",
        "    )\n",
        "    return src, tgt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxt8tAc5KZRw"
      },
      "source": [
        "Helper functions to convert the sentences into vector. Given a list of sentence, we use a Sentencepiece model to tokenize it and convert it into a list of word IDs.\n",
        "\n",
        "Check [Sentencepiece documentations](https://github.com/google/sentencepiece/blob/master/python/README.md#usage) to see how to use the models to convert text into ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLLb5nPk2bh"
      },
      "outputs": [],
      "source": [
        "def preprocess(sp, data):\n",
        "    # TO-DO: use the Sentencepiece model to tokenize and turn the sentences into ids\n",
        "    # remember to add bos and eos tokens (from the Sentencepiece model) to the beginning and end of each sentence\n",
        "\n",
        "    encoded_data = sp.encode_as_ids(data)\n",
        "    encoded_data = [[sp.bos_id()]+ sentence + [sp.eos_id()] for sentence in encoded_data]\n",
        "\n",
        "    return encoded_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ9VcIcgzStu"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "Implement the main training loop here. This function takes in one batch of input and target tensors and does a forward pass, backward pass, and weight updates. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_N-h0dp0k8wo"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    input_tensor,\n",
        "    target_tensor,\n",
        "    encoder,\n",
        "    decoder,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    use_teacher_forcing,\n",
        "    training=True,\n",
        "):\n",
        "    if training:\n",
        "        # TO-DO: Reset/Zero parameter gradients of the optimizer. Hint: https://pytorch.org/tutorials/recipes/recipes/zeroing_out_gradients.html#zero-the-gradients-while-training-the-network\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    encoder_output, encoder_hidden = encoder(input_tensor)\n",
        "    dec_length = target_tensor.size()[-1]\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        # Remember that we are giving target[:-1] as the input, and matching targe[1:] with the output\n",
        "        \n",
        "        # TO-DO: Run decoder by providing target and encoder_hidden as input\n",
        "        decoder_output, _ = decoder(target_tensor[:,:-1], encoder_hidden)\n",
        "\n",
        "        # TO-DO: Calculate loss\n",
        "        loss = criterion(decoder_output.transpose(-1, -2), target_tensor[:,1:])\n",
        "\n",
        "    else:\n",
        "        dec_length = 0\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        decoder_input = torch.tensor(\n",
        "            [[SOS_token]] * target_tensor.size()[0], device=device\n",
        "        )\n",
        "        last_hidden = encoder_hidden\n",
        "        for di in range(target_tensor.size()[-1] - 1):\n",
        "            dec_length += 1\n",
        "            # TO-DO: Run decoder by providing decoder_input and decoder_hidden as input\n",
        "            decoder_output, last_hidden = decoder(decoder_input, last_hidden)\n",
        "\n",
        "            # Take the top output of current timestep of decoder. This will be input to next timestep\n",
        "            topv, topi = decoder_output.topk(1, dim=-1)\n",
        "            decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output.squeeze(-2), target_tensor[:,di+1])\n",
        "            if not training and torch.sum(decoder_input) == 0:\n",
        "                break\n",
        "\n",
        "    if training:\n",
        "        # TO-DO: Backprop by calling backward() function on loss\n",
        "        loss.backward()\n",
        "\n",
        "        # TO-DO: Update weights using step() on both encoder_optimizer and decoder_optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "    return loss.item() / dec_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xV9QrE_lGyb"
      },
      "outputs": [],
      "source": [
        "def trainIters(\n",
        "    encoder,\n",
        "    decoder,\n",
        "    n_iters,\n",
        "    train_loader,\n",
        "    valid_loader,\n",
        "    learning_rate=0.001,\n",
        "    teacher_forcing_ratio=0.5,\n",
        "):\n",
        "    # Initialize AdamW optimizer for both encoder and decoder\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        [{\"params\": encoder.parameters()}, {\"params\": decoder.parameters()}],\n",
        "        lr=learning_rate,\n",
        "    )\n",
        "\n",
        "    # We will be using cross entropy as the criterion\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    epoch_train_losses = []\n",
        "    epoch_valid_losses = []\n",
        "\n",
        "    # In each epoch, we go through all training examples\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        # Train\n",
        "        train_loss = []\n",
        "        for input_tensor, output_tensor in tqdm(train_loader):\n",
        "            use_teacherforcing = (\n",
        "                True if random.random() < teacher_forcing_ratio else False\n",
        "            )\n",
        "\n",
        "            loss = train(\n",
        "                input_tensor.to(device),\n",
        "                output_tensor.to(device),\n",
        "                encoder,\n",
        "                decoder,\n",
        "                optimizer,\n",
        "                criterion,\n",
        "                use_teacherforcing,\n",
        "            )\n",
        "            train_loss.append(loss)\n",
        "\n",
        "        # Validate\n",
        "        valid_loss = []\n",
        "        for input_tensor, output_tensor in tqdm(valid_loader):\n",
        "            loss = train(\n",
        "                input_tensor.to(device),\n",
        "                output_tensor.to(device),\n",
        "                encoder,\n",
        "                decoder,\n",
        "                optimizer,\n",
        "                criterion,\n",
        "                False,\n",
        "                training=False,\n",
        "            )\n",
        "            valid_loss.append(loss)\n",
        "\n",
        "        avg_train_loss = np.mean(train_loss)\n",
        "        avg_valid_loss = np.mean(valid_loss)\n",
        "\n",
        "        print(\n",
        "            \"Epoch: {}/{}. Avg Train Loss: {}. Avg Valid Loss: {}\".format(\n",
        "                iter, n_iters, avg_train_loss, avg_valid_loss\n",
        "            )\n",
        "        )\n",
        "\n",
        "        epoch_train_losses.append(avg_train_loss)\n",
        "        epoch_valid_losses.append(avg_valid_loss)\n",
        "\n",
        "    return epoch_train_losses, epoch_valid_losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLCVURlPzlUb"
      },
      "source": [
        "Define the hyperparameters. You can try different settings.\n",
        "\n",
        "If you are running into memory issues, decrease the BATCH_SIZE or EMB_SIZE or HIDDEN_SIZE.\n",
        "\n",
        "If you have access to more powerful hardware, you can increase the BATCH_SIZE, EMB_SIZE, HIDDEN_SIZE, NUM_EPOCHS to train longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYye7pQOhNC2"
      },
      "outputs": [],
      "source": [
        "# Model Training Hyper-Parameters\n",
        "MAX_LENGTH = 20\n",
        "EMB_SIZE = 100\n",
        "HIDDEN_SIZE = 256\n",
        "NUM_LAYERS = 2\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 1e-3\n",
        "DROPOUT = 0.3\n",
        "TEACHER_FORCING_RATIO = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRXO20epC-V-"
      },
      "source": [
        "Turn sequences of text into sequences of ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C4pGP0XMAay"
      },
      "outputs": [],
      "source": [
        "# reload thesentencepiece models if necessary\n",
        "en_sp = spm.SentencePieceProcessor(model_file=\"en-zh.en.model\")\n",
        "zh_sp = spm.SentencePieceProcessor(model_file=\"en-zh.zh.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJPqb8eLQBgO"
      },
      "outputs": [],
      "source": [
        "src = preprocess(en_sp, train_data[\"en\"])\n",
        "tgt = preprocess(zh_sp, train_data[\"zh\"])\n",
        "train_dataset = MTDataset(src, tgt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7IiXc67pnDF"
      },
      "outputs": [],
      "source": [
        "src = preprocess(en_sp, valid_data[\"en\"])\n",
        "tgt = preprocess(zh_sp, valid_data[\"zh\"])\n",
        "valid_dataset = MTDataset(src, tgt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xij73iGGSBX"
      },
      "source": [
        "Generate training and validation splits and dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwPvXKWeGSYo"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True\n",
        ")\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyUlEf2QDLcx"
      },
      "source": [
        "Now we can create the models and start the training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFX50FjYMAaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f12e46e-7302-4665-b26e-0bdcf2c64ab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:26<00:00, 12.69it/s]\n",
            "100%|██████████| 42/42 [00:00<00:00, 50.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/20. Avg Train Loss: 1.3853180341375855. Avg Valid Loss: 5.1026242803367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:21<00:00, 15.32it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 38.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/20. Avg Train Loss: 1.4087164385925695. Avg Valid Loss: 4.958325295454125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:21<00:00, 15.31it/s]\n",
            "100%|██████████| 42/42 [00:00<00:00, 46.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/20. Avg Train Loss: 1.4266852844051794. Avg Valid Loss: 4.603003003590466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:22<00:00, 15.05it/s]\n",
            "100%|██████████| 42/42 [00:00<00:00, 46.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4/20. Avg Train Loss: 1.364247611542441. Avg Valid Loss: 4.4831377485376045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:23<00:00, 14.49it/s]\n",
            "100%|██████████| 42/42 [00:00<00:00, 45.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5/20. Avg Train Loss: 1.306155278614417. Avg Valid Loss: 4.29059495343416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:22<00:00, 15.17it/s]\n",
            "100%|██████████| 42/42 [00:00<00:00, 42.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6/20. Avg Train Loss: 1.406256360241278. Avg Valid Loss: 4.210012896152907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:22<00:00, 15.04it/s]\n",
            "100%|██████████| 42/42 [00:00<00:00, 43.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7/20. Avg Train Loss: 1.3236968723390299. Avg Valid Loss: 4.0527035246354775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:22<00:00, 15.07it/s]\n",
            "100%|██████████| 42/42 [00:00<00:00, 44.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8/20. Avg Train Loss: 1.2871304494276798. Avg Valid Loss: 3.9649543023204226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:21<00:00, 15.49it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 34.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9/20. Avg Train Loss: 1.1901201510932322. Avg Valid Loss: 4.0730608126815815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:22<00:00, 15.17it/s]\n",
            "100%|██████████| 42/42 [00:00<00:00, 42.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/20. Avg Train Loss: 1.332144196293397. Avg Valid Loss: 3.800674211907799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:21<00:00, 15.40it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 41.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11/20. Avg Train Loss: 1.1533670747129663. Avg Valid Loss: 3.952240179673918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:22<00:00, 15.16it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 32.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12/20. Avg Train Loss: 1.2330925665712256. Avg Valid Loss: 3.54468909726283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:21<00:00, 15.43it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 41.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13/20. Avg Train Loss: 1.1568741389687105. Avg Valid Loss: 3.6399159193598485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:22<00:00, 14.92it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 40.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14/20. Avg Train Loss: 1.3101731091931557. Avg Valid Loss: 3.5296945942974296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:22<00:00, 15.13it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 39.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15/20. Avg Train Loss: 1.1994090851357062. Avg Valid Loss: 3.3976958104128423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:21<00:00, 15.55it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 28.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16/20. Avg Train Loss: 1.0758567787520708. Avg Valid Loss: 3.3793369875144768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:21<00:00, 15.36it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 37.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17/20. Avg Train Loss: 1.0773320827748798. Avg Valid Loss: 3.2331873172209233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:22<00:00, 15.06it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 38.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18/20. Avg Train Loss: 1.1178809100958371. Avg Valid Loss: 3.2741016841770594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:22<00:00, 15.03it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 28.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19/20. Avg Train Loss: 1.1489128569413891. Avg Valid Loss: 3.2012481652265854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 334/334 [00:21<00:00, 15.26it/s]\n",
            "100%|██████████| 42/42 [00:01<00:00, 35.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20/20. Avg Train Loss: 1.1403109400952185. Avg Valid Loss: 3.2593243398458958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "encoder_eng_zh = EncoderRNN(en_sp.vocab_size(), EMB_SIZE, HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
        "decoder_eng_zh = DecoderRNN(zh_sp.vocab_size(), EMB_SIZE, HIDDEN_SIZE, num_layers=NUM_LAYERS*2, dropout=DROPOUT).to(device)\n",
        "SOS_token = en_sp.bos_id()\n",
        "\n",
        "avg_train_losses_zh, avg_valid_losses_zh = trainIters(\n",
        "    encoder_eng_zh, decoder_eng_zh, NUM_EPOCHS, train_loader, valid_loader, learning_rate=LEARNING_RATE, teacher_forcing_ratio=TEACHER_FORCING_RATIO\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoxlVmdLDdaE"
      },
      "source": [
        "Save your models and training log after training. You should download the weights and logs from Colab so you don't have to train the model again when you start working on the rest of the notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vscJES10D45a"
      },
      "outputs": [],
      "source": [
        "torch.save(encoder_eng_zh, 'en_zh_encoder.pt')\n",
        "torch.save(decoder_eng_zh, 'en_zh_decoder.pt')\n",
        "\n",
        "with open(\"losses_en_zh.txt\", \"w\") as fp:\n",
        "    for i, j in zip(avg_train_losses_zh, avg_valid_losses_zh):\n",
        "        fp.write(\"{:.12f} {:.12f}\\n\".format(i, j))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW17lwRuEcNh"
      },
      "source": [
        "### Checkpoint 3\n",
        "\n",
        "Use this function to plot the training and evaluation losses. What trends can you observe?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(train_losses, valid_losses):\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, ax = plt.subplots()\n",
        "    x = np.arange(len(train_losses)) + 1\n",
        "    ax.plot(x, train_losses, 'o-', label='training')\n",
        "    ax.plot(x, valid_losses, 'o-', label='validation')\n",
        "    ax.set_xlabel('epochs')\n",
        "    ax.set_ylabel('loss values')\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WzrtphY_tvbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(avg_train_losses_zh, avg_valid_losses_zh)"
      ],
      "metadata": {
        "id": "mLlgaoNztwvy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "5415eb5f-0231-4473-d43d-241925e3290c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ehweWG2ztnl"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the baseline decoding method that generate the tokens greedily."
      ],
      "metadata": {
        "id": "cgXkV6X6j8xG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AX1gbuhRgC2a"
      },
      "outputs": [],
      "source": [
        "def predict(encoder, decoder, sentence, src_sp, tgt_sp):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = [[src_sp.bos_id()] + src_sp.encode_as_ids(sentence) + [src_sp.eos_id()]]\n",
        "        input_tensor = torch.tensor(input_tensor, device=device)\n",
        "\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_input = torch.tensor([[tgt_sp.bos_id()]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_ids = []\n",
        "\n",
        "        for di in range(MAX_LENGTH):\n",
        "            # TO-DO: generate next output and hidden state from decoder_input and decoder_hidden\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, encoder_hidden)\n",
        "\n",
        "            # TO-DO: get the id of the most likely item from decoder_output\n",
        "            _, topi = decoder_output.data.topk(1,  dim=-1)\n",
        "            if topi.item() == tgt_sp.eos_id():\n",
        "                break\n",
        "            else:\n",
        "                decoded_ids.append(topi.item())\n",
        "\n",
        "            decoder_input = topi.squeeze(-1).detach()\n",
        "        # TO-DO: use the Sentencepiece model to convert the ids back to a string\n",
        "        decoded_words = tgt_sp.decode(decoder_input)\n",
        "\n",
        "        return decoded_words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bonus points (20%): implement beam search. This is optional.\n",
        "\n",
        "To make autograding work, your beam_search should return a list of predictions from the most likely to the least likely, and each prediction should be a tuple of (score, text). For example:\n",
        "\n",
        "```\n",
        "[(0,2, \"Thank you\"), (0.1, \"Thanks\"), (0.01, \"Thanks you\")]\n",
        "```"
      ],
      "metadata": {
        "id": "0LEO_r6AkaSB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSs9bH5pdRho"
      },
      "outputs": [],
      "source": [
        "def beam_search(encoder, decoder, sentence, src_sp, tgt_sp, beam_size=5):\n",
        "    assert beam_size > 1, \"if beam_size = 1, then that's greedy search\"\n",
        "    with torch.no_grad():\n",
        "        # TO-DO: Just like predict() but instead of the topk with 1, take topk with beam_size and rank sort the beam for the more likely probability\n",
        "        raise NotImplemented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN6VGxL4z3JY"
      },
      "source": [
        "Try out a random input. \n",
        "\n",
        "1. Does the output make sense if given an input from the training set?\n",
        "2. Does the output make sense if given an arbitrary input?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU4WSPHXHb5f"
      },
      "outputs": [],
      "source": [
        "# reload the encoder and decoder if necessary\n",
        "encoder_eng_zh = torch.load('en_zh_encoder.pt')\n",
        "decoder_eng_zh = torch.load('en_zh_decoder.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tge_5xmLrSkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "fbcd6168-d70a-4a3e-d326-ab57d0f607ca"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-b20ffd27531c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m print(\n\u001b[0;32m----> 2\u001b[0;31m     predict(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mencoder_eng_zh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdecoder_eng_zh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"What gives us the courage?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-bdbe90e2405f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(encoder, decoder, sentence, src_sp, tgt_sp)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# TO-DO: use the Sentencepiece model to convert the ids back to a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdecoded_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_sp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sentencepiece/__init__.py\u001b[0m in \u001b[0;36mDecode\u001b[0;34m(self, input, out_type, num_threads)\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unknown output or input type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: unknown output or input type"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    predict(\n",
        "        encoder_eng_zh,\n",
        "        decoder_eng_zh,\n",
        "        \"What gives us the courage?\",\n",
        "        en_sp,\n",
        "        zh_sp,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3H9Ac7eMHeL"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    beam_search(\n",
        "        encoder_eng_zh,\n",
        "        decoder_eng_zh,\n",
        "        \"What gives us the courage?\",\n",
        "        en_sp,\n",
        "        zh_sp,\n",
        "        beam_size=5,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rITuKy0o_ayD"
      },
      "source": [
        "Define a function to generate model predictions and save them in a file. Download your model predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7vE5rlDhsFx"
      },
      "outputs": [],
      "source": [
        "def generate_and_save(valid_inputs, encoder, decoder, src_sp, tgt_sp, beam_size=1, saveloc=\"preds.zh\"):\n",
        "    generated_sents = []\n",
        "    for src_sent in tqdm(valid_inputs):\n",
        "        if beam_size <= 1:\n",
        "            tgt_sent = predict(encoder, decoder, src_sent, src_sp, tgt_sp)\n",
        "        else:\n",
        "            # change this if your beam search returns something different\n",
        "            tgt_sent = beam_search(encoder, decoder, src_sent, src_sp, tgt_sp, beam_size)[0][1]\n",
        "        # if the decoded string is empty, we replace it with the Sentencepiece unk character\n",
        "        if len(tgt_sent) == 0:\n",
        "            tgt_sent = \"⁇\"\n",
        "        generated_sents.append(tgt_sent)\n",
        "    with open(saveloc, \"w\") as fout:\n",
        "        fout.write(\"\\n\".join(generated_sents))\n",
        "    return generated_sents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxzpFaKQ0EjN"
      },
      "source": [
        "### Checkpoint 4\n",
        "\n",
        "Calculate BLEU and CHRF scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpWdzp-nuoS5"
      },
      "outputs": [],
      "source": [
        "with open(\"valid.zh\") as fin:\n",
        "    refs = fin.read().strip().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EpUbol2u1nh"
      },
      "outputs": [],
      "source": [
        "preds = generate_and_save(valid_data[\"en\"], encoder_eng_zh, decoder_eng_zh, en_sp, zh_sp, saveloc=\"valid_preds.zh\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The BLEU score will be very low for the baseline model."
      ],
      "metadata": {
        "id": "dN6XTgEazwth"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcfJYlvytFrc"
      },
      "outputs": [],
      "source": [
        "bleu = BLEU(tokenize=\"flores101\")\n",
        "print(bleu.corpus_score(preds, refs))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should get at least 25 CHRF score."
      ],
      "metadata": {
        "id": "PJQUow9Dz2iH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRRB5hjwvQcN"
      },
      "outputs": [],
      "source": [
        "chrf = CHRF()\n",
        "print(chrf.corpus_score(preds, refs))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}